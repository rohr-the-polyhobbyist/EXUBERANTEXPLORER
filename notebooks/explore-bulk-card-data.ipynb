{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Card data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,os,sys,gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tithe_extractor.scryfall_api import make_api_request\n",
    "from tithe_extractor.constants import HEADERS, TIMEOUT\n",
    "from tithe_extractor.datautils import load_raw_cards_data\n",
    "\n",
    "# Paths\n",
    "paths_dict = json.load(open('paths.json'))\n",
    "metadata_path = paths_dict['metadata']  # write your own path here - metadata path\n",
    "card_json_path = paths_dict['cards_json']  # write your own path here - card path\n",
    "card_csv_path = paths_dict['cards_csv']  # write your own path here - card csv path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download card data (if you have metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bulk card data path from the metadata\n",
    "metadata = json.loads(open(metadata_path).read())\n",
    "download_uri = metadata['data'][0]['download_uri']\n",
    "print(download_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the bulk card data\n",
    "response = make_api_request(download_uri,headers=HEADERS, timeout=TIMEOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one of the json objects in the response\n",
    "response.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it to a file (uncompressed - assuming it's not too big)\n",
    "with open(card_json_path, \"w+\", encoding=\"utf-8\") as f:\n",
    "        for item in response.json():\n",
    "            json.dump(item, f)\n",
    "            f.write(\"\\n\")\n",
    "        print(\"Bulk card data saved to file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the card data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have the card data saved to a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already have the bulk card data saved to a file, you can load it like this\n",
    "df = load_raw_cards_data(card_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you don't have the card data saved to csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to store extracted json objects\n",
    "extracted_objs = []\n",
    "err_count = 0\n",
    "line_count = 0\n",
    "# open the file in read mode\n",
    "with open(card_json_path, 'rt') as file:\n",
    "    # Iterate over each line\n",
    "    for line in file:\n",
    "        # Parse the JSON object from the current line\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            extracted_objs.append(json_obj)\n",
    "            line_count += 1\n",
    "        except json.JSONDecodeError:\n",
    "            print('Line is not a valid JSON object')\n",
    "            err_count += 1\n",
    "print(f\"Extracted {line_count} JSON objects with {err_count} errors.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Saving/Loading the DataFrame to/from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_objs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now is the time to start thinking about modeling the data. We can start by examining the keys of the first object in the list.\n",
    "x = [key for key in extracted_objs[0].keys()]\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's print the keys in a readable way\n",
    "for i in range(0, len(x), 5):\n",
    "    print(x[i:i+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some keys of interest\n",
    "keys_of_interest = [\n",
    "    'id',\n",
    "    'oracle_id',\n",
    "    'name',\n",
    "    'mana_cost',\n",
    "    'cmc',\n",
    "    'type_line',\n",
    "    'oracle_text',\n",
    "    'colors',\n",
    "    'color_identity',\n",
    "    'set',\n",
    "    'rarity',\n",
    "    'power',\n",
    "    'toughness',\n",
    "    'loyalty',\n",
    "    'keywords',\n",
    "    'legalities',\n",
    "    'game_changer',\n",
    "    'edhrec_rank',\n",
    "    'prices',\n",
    "    'rulings_uri',\n",
    "    'related_uris',\n",
    "    'purchase_uris',\n",
    "    'image_uris'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the extracted objects using keys of interest\n",
    "df = pd.DataFrame(extracted_objs)[keys_of_interest]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the object columns to string\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out this dataframe to a csv file\n",
    "df.to_csv(card_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(card_csv_path,keep_default_na=False)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert to float\n",
    "df2['edhrec_rank'] = df2['edhrec_rank'].replace('', np.nan) # replace empty strings with NaN\n",
    "df2['edhrec_rank'] = df2['edhrec_rank'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for mismatches between the original and reloaded dataframes\n",
    "mismatched = df[df != df2]\n",
    "# Look at the mismatches and see if you can account for them all before relying on the reloaded data.\n",
    "mismatched.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to load the cards.csv data and transform it correctly\n",
    "def load_raw_cards_data(path):\n",
    "    \"\"\"\"\n",
    "    Load the raw cards data from the specified path and cast the columns to the correct data types to match the original data loaded from json.\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = pd.read_csv(path, keep_default_na=False)\n",
    "    # Cast the object columns to string\n",
    "    # for col in df.select_dtypes(include='object').columns:\n",
    "    #     df[col] = df[col].astype(str)\n",
    "    # Cast the edhrec_rank column to float\n",
    "    df['edhrec_rank'] = df['edhrec_rank'].replace('', np.nan) # replace empty strings with NaN\n",
    "    df['edhrec_rank'] = df['edhrec_rank'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly validate the function\n",
    "df3 = load_raw_cards_data(card_csv_path)\n",
    "mismatched = df2[df != df3]\n",
    "mismatched.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we are all good to start exploring the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric Values (cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at our numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMC has a huge range, let's look at the distribution\n",
    "df['cmc'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might be worth it to just remove the cards with weird cmc values\n",
    "df = df[df['cmc'].isin(range(16))] # Get rid of cards with cmc > 15\n",
    "df = df[df['cmc'] != 0.05] # Get rid of cards with cmc = 0.05\n",
    "# Look at the value counts again\n",
    "df['cmc'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:10,'mana_cost':'cmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Let's encode the mana cost by the number of colored mana symbols\n",
    "# First we will make a function to count the number of colored mana symbols of each color in a string\n",
    "def count_colored_mana_symbols(mana_cost):\n",
    "    \"\"\"\n",
    "    Count the number of each colored mana symbol in a mana cost string.\n",
    "    \"\"\"\n",
    "    # Define the colored mana symbols\n",
    "    colored_mana_symbols = ['W', 'U', 'B', 'R', 'G']\n",
    "    # Initialize the count dictionary\n",
    "    count_dict = {symbol: 0 for symbol in colored_mana_symbols}\n",
    "    count_dict['C'] = 0  # Colorless mana\n",
    "    count_dict['uncolored'] = 0  # Uncolored mana\n",
    "\n",
    "    # Iterate over the colored mana symbols\n",
    "    for symbol in colored_mana_symbols:\n",
    "        # Count the number of times the symbol appears in the mana cost\n",
    "        count_dict[symbol] = mana_cost.count(symbol)\n",
    "    \n",
    "    # Count the number of colorless mana symbols\n",
    "    count_dict['C'] = mana_cost.count('{C}')\n",
    "    \n",
    "    # Count the number of uncolored mana symbols (indicated by a number)\n",
    "    uncolored_mana = re.findall(r'\\{(\\d+)\\}', mana_cost)\n",
    "    count_dict['uncolored'] = sum(int(x) for x in uncolored_mana)\n",
    "    \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we test the function and also check out the different mana cost values. Also need to account for split costs like {W/U}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
